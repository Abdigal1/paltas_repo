{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be52da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "#from skimage import io\n",
    "#import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "#from meta_load import *\n",
    "import pickle\n",
    "\n",
    "sys.path.append(os.path.join(\"..\",'Data_prep'))\n",
    "sys.path.append(os.path.join(\"..\",'Models2'))\n",
    "\n",
    "from Custom_dataloader import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#DB=\"/run/user/1000/gvfs/afp-volume:host=MyCloudPR4100.local,user=admin,volume=Paltas_DataBase/Data_Base\"\n",
    "#DBd=\"//MYCLOUDPR4100/Paltas_DataBase/Data_Base\"\n",
    "#DB=\"//MYCLOUDPR4100/Paltas_DataBase\"\n",
    "DB=\"/home/liiarpi-01/proyectopaltas/Local_data_base/Data_Base_v2\"\n",
    "meta_dir=\"/home/liiarpi-01/proyectopaltas/Local_data_base/metadata_GMVAE_A1_2\"\n",
    "#d_t=transforms.Compose([phantom_segmentation(False)])\n",
    "\n",
    "datar=Dataset_direct(root_dir=DB,ImType=['PhantomRGB'],Intersec=False,retrieve_img=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d891e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "metad=np.array(os.listdir(meta_dir)[1:])\n",
    "metad_dict=np.vectorize(lambda meta: pickle.load(open(os.path.join(meta_dir,meta),'rb')))(metad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a7bbf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(array_dict):\n",
    "    DF=pd.DataFrame(array_dict)\n",
    "    for k in list(array_dict[0].keys()):\n",
    "        if isinstance(metad_dict[0][k],list):\n",
    "            DF[k]=np.vectorize(lambda rd:rd[k][0])(array_dict)\n",
    "        else:\n",
    "            for i in np.arange(array_dict[0][k].shape[1]):\n",
    "                #DF[k+\"_\"+str(i)]=metad_dict[0][k][0,i]\n",
    "                DF[k+\"_\"+str(i)]=np.vectorize(lambda rd:rd[k][0,i])(array_dict)\n",
    "    DF.drop(0,axis=1,inplace=True)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dafa70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers=[]\n",
    "for k in list(metad_dict[0].keys()):\n",
    "    if isinstance(metad_dict[0][k],list):\n",
    "        headers.append(k)\n",
    "        #DF[k]=metad_dict[0][k][0]\n",
    "        DF[k]=np.vectorize(lambda rd:rd['k'][0])(metad_dict)\n",
    "    else:\n",
    "        for i in np.arange(metad_dict[0][k].shape[1]):\n",
    "            print(headers)\n",
    "            headers.append(k+\"_\"+str(i))\n",
    "            #DF[k+\"_\"+str(i)]=metad_dict[0][k][0]\n",
    "            #DF[k+\"_\"+str(i)]=metad_dict[0][k][0,i]\n",
    "            DF[k+\"_\"+str(i)]=np.vectorize(lambda rd:rd['z_x_mu'][0,i])(metad_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c24b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z_x_mu_0</th>\n",
       "      <th>z_x_mu_1</th>\n",
       "      <th>z_x_mu_2</th>\n",
       "      <th>z_x_mu_3</th>\n",
       "      <th>z_x_mu_4</th>\n",
       "      <th>z_x_logsig_0</th>\n",
       "      <th>z_x_logsig_1</th>\n",
       "      <th>z_x_logsig_2</th>\n",
       "      <th>z_x_logsig_3</th>\n",
       "      <th>z_x_logsig_4</th>\n",
       "      <th>...</th>\n",
       "      <th>py_5</th>\n",
       "      <th>py_6</th>\n",
       "      <th>py_7</th>\n",
       "      <th>py_8</th>\n",
       "      <th>py_9</th>\n",
       "      <th>py_10</th>\n",
       "      <th>py_11</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.226943</td>\n",
       "      <td>-0.735718</td>\n",
       "      <td>-0.644057</td>\n",
       "      <td>1.430477</td>\n",
       "      <td>1.710736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083011</td>\n",
       "      <td>0.083312</td>\n",
       "      <td>0.083465</td>\n",
       "      <td>0.083256</td>\n",
       "      <td>0.083507</td>\n",
       "      <td>0.083275</td>\n",
       "      <td>0.083409</td>\n",
       "      <td>6_A</td>\n",
       "      <td>16_junio_1</td>\n",
       "      <td>N_Exceso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.686828</td>\n",
       "      <td>-2.931506</td>\n",
       "      <td>-0.840768</td>\n",
       "      <td>-5.264722</td>\n",
       "      <td>-4.424634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083339</td>\n",
       "      <td>0.083519</td>\n",
       "      <td>0.083147</td>\n",
       "      <td>0.083286</td>\n",
       "      <td>0.083396</td>\n",
       "      <td>0.083619</td>\n",
       "      <td>0.083072</td>\n",
       "      <td>4_D</td>\n",
       "      <td>29_marzo_1</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.622476</td>\n",
       "      <td>-1.276294</td>\n",
       "      <td>2.713542</td>\n",
       "      <td>-1.909442</td>\n",
       "      <td>1.363258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083331</td>\n",
       "      <td>0.083345</td>\n",
       "      <td>0.083367</td>\n",
       "      <td>0.083316</td>\n",
       "      <td>0.083177</td>\n",
       "      <td>0.083327</td>\n",
       "      <td>0.083345</td>\n",
       "      <td>19_G</td>\n",
       "      <td>16_junio_1</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.814916</td>\n",
       "      <td>1.993920</td>\n",
       "      <td>0.985770</td>\n",
       "      <td>1.645794</td>\n",
       "      <td>1.756575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083531</td>\n",
       "      <td>0.082878</td>\n",
       "      <td>0.083441</td>\n",
       "      <td>0.083399</td>\n",
       "      <td>0.083177</td>\n",
       "      <td>0.083360</td>\n",
       "      <td>0.083492</td>\n",
       "      <td>4_A</td>\n",
       "      <td>26_mayo_1</td>\n",
       "      <td>N_Exceso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.692554</td>\n",
       "      <td>-0.434313</td>\n",
       "      <td>0.967884</td>\n",
       "      <td>1.223063</td>\n",
       "      <td>-0.156023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083291</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.083330</td>\n",
       "      <td>0.083356</td>\n",
       "      <td>0.083263</td>\n",
       "      <td>0.083355</td>\n",
       "      <td>0.083321</td>\n",
       "      <td>15_F</td>\n",
       "      <td>28_abril_2</td>\n",
       "      <td>H75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>3.481685</td>\n",
       "      <td>0.067505</td>\n",
       "      <td>1.668355</td>\n",
       "      <td>-0.666159</td>\n",
       "      <td>-0.202151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083316</td>\n",
       "      <td>0.083132</td>\n",
       "      <td>0.083371</td>\n",
       "      <td>0.083403</td>\n",
       "      <td>0.083257</td>\n",
       "      <td>0.083316</td>\n",
       "      <td>0.083412</td>\n",
       "      <td>2_D</td>\n",
       "      <td>19_mayo_2</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>1.482849</td>\n",
       "      <td>1.435127</td>\n",
       "      <td>1.106577</td>\n",
       "      <td>2.310173</td>\n",
       "      <td>0.894225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083384</td>\n",
       "      <td>0.083361</td>\n",
       "      <td>0.083287</td>\n",
       "      <td>0.083326</td>\n",
       "      <td>0.083239</td>\n",
       "      <td>0.083459</td>\n",
       "      <td>0.083250</td>\n",
       "      <td>9_C</td>\n",
       "      <td>9_julio_1</td>\n",
       "      <td>K_Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>-4.504982</td>\n",
       "      <td>-3.483152</td>\n",
       "      <td>-1.558088</td>\n",
       "      <td>-3.040207</td>\n",
       "      <td>-1.875820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083356</td>\n",
       "      <td>0.083463</td>\n",
       "      <td>0.083222</td>\n",
       "      <td>0.083287</td>\n",
       "      <td>0.083311</td>\n",
       "      <td>0.083530</td>\n",
       "      <td>0.083164</td>\n",
       "      <td>13_E</td>\n",
       "      <td>14_abril_2</td>\n",
       "      <td>H50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>1.253831</td>\n",
       "      <td>3.146727</td>\n",
       "      <td>1.778033</td>\n",
       "      <td>0.891150</td>\n",
       "      <td>2.803267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082976</td>\n",
       "      <td>0.082970</td>\n",
       "      <td>0.083466</td>\n",
       "      <td>0.083428</td>\n",
       "      <td>0.083575</td>\n",
       "      <td>0.083248</td>\n",
       "      <td>0.083530</td>\n",
       "      <td>8_F</td>\n",
       "      <td>19_agosto_1</td>\n",
       "      <td>H75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>2.079777</td>\n",
       "      <td>2.010072</td>\n",
       "      <td>0.067656</td>\n",
       "      <td>1.266374</td>\n",
       "      <td>2.068118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082943</td>\n",
       "      <td>0.083446</td>\n",
       "      <td>0.083357</td>\n",
       "      <td>0.083362</td>\n",
       "      <td>0.083607</td>\n",
       "      <td>0.083268</td>\n",
       "      <td>0.083258</td>\n",
       "      <td>12_C</td>\n",
       "      <td>26_mayo_1</td>\n",
       "      <td>K_Control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3852 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      z_x_mu_0  z_x_mu_1  z_x_mu_2  z_x_mu_3  z_x_mu_4  z_x_logsig_0  \\\n",
       "0     1.226943 -0.735718 -0.644057  1.430477  1.710736           0.0   \n",
       "1    -0.686828 -2.931506 -0.840768 -5.264722 -4.424634           0.0   \n",
       "2     0.622476 -1.276294  2.713542 -1.909442  1.363258           0.0   \n",
       "3     1.814916  1.993920  0.985770  1.645794  1.756575           0.0   \n",
       "4     1.692554 -0.434313  0.967884  1.223063 -0.156023           0.0   \n",
       "...        ...       ...       ...       ...       ...           ...   \n",
       "3847  3.481685  0.067505  1.668355 -0.666159 -0.202151           0.0   \n",
       "3848  1.482849  1.435127  1.106577  2.310173  0.894225           0.0   \n",
       "3849 -4.504982 -3.483152 -1.558088 -3.040207 -1.875820           0.0   \n",
       "3850  1.253831  3.146727  1.778033  0.891150  2.803267           0.0   \n",
       "3851  2.079777  2.010072  0.067656  1.266374  2.068118           0.0   \n",
       "\n",
       "      z_x_logsig_1  z_x_logsig_2  z_x_logsig_3  z_x_logsig_4  ...      py_5  \\\n",
       "0              0.0           0.0           0.0           0.0  ...  0.083011   \n",
       "1              0.0           0.0           0.0           0.0  ...  0.083339   \n",
       "2              0.0           0.0           0.0           0.0  ...  0.083331   \n",
       "3              0.0           0.0           0.0           0.0  ...  0.083531   \n",
       "4              0.0           0.0           0.0           0.0  ...  0.083291   \n",
       "...            ...           ...           ...           ...  ...       ...   \n",
       "3847           0.0           0.0           0.0           0.0  ...  0.083316   \n",
       "3848           0.0           0.0           0.0           0.0  ...  0.083384   \n",
       "3849           0.0           0.0           0.0           0.0  ...  0.083356   \n",
       "3850           0.0           0.0           0.0           0.0  ...  0.082976   \n",
       "3851           0.0           0.0           0.0           0.0  ...  0.082943   \n",
       "\n",
       "          py_6      py_7      py_8      py_9     py_10     py_11  Place  \\\n",
       "0     0.083312  0.083465  0.083256  0.083507  0.083275  0.083409    6_A   \n",
       "1     0.083519  0.083147  0.083286  0.083396  0.083619  0.083072    4_D   \n",
       "2     0.083345  0.083367  0.083316  0.083177  0.083327  0.083345   19_G   \n",
       "3     0.082878  0.083441  0.083399  0.083177  0.083360  0.083492    4_A   \n",
       "4     0.083300  0.083330  0.083356  0.083263  0.083355  0.083321   15_F   \n",
       "...        ...       ...       ...       ...       ...       ...    ...   \n",
       "3847  0.083132  0.083371  0.083403  0.083257  0.083316  0.083412    2_D   \n",
       "3848  0.083361  0.083287  0.083326  0.083239  0.083459  0.083250    9_C   \n",
       "3849  0.083463  0.083222  0.083287  0.083311  0.083530  0.083164   13_E   \n",
       "3850  0.082970  0.083466  0.083428  0.083575  0.083248  0.083530    8_F   \n",
       "3851  0.083446  0.083357  0.083362  0.083607  0.083268  0.083258   12_C   \n",
       "\n",
       "             Date      Class  \n",
       "0      16_junio_1   N_Exceso  \n",
       "1      29_marzo_1    Control  \n",
       "2      16_junio_1    Control  \n",
       "3       26_mayo_1   N_Exceso  \n",
       "4      28_abril_2       H75%  \n",
       "...           ...        ...  \n",
       "3847    19_mayo_2    Control  \n",
       "3848    9_julio_1  K_Control  \n",
       "3849   14_abril_2       H50%  \n",
       "3850  19_agosto_1       H75%  \n",
       "3851    26_mayo_1  K_Control  \n",
       "\n",
       "[3852 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mDF=get_dataframe(metad_dict)\n",
    "data=mDF\n",
    "mDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "008c7736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['z_x_mu_0', 'z_x_mu_1', 'z_x_mu_2', 'z_x_mu_3', 'z_x_mu_4',\n",
      "       'z_x_logsig_0', 'z_x_logsig_1', 'z_x_logsig_2', 'z_x_logsig_3',\n",
      "       'z_x_logsig_4', 'w_x_mu_0', 'w_x_mu_1', 'w_x_mu_2', 'w_x_mu_3',\n",
      "       'w_x_mu_4', 'w_x_logsig_0', 'w_x_logsig_1', 'w_x_logsig_2',\n",
      "       'w_x_logsig_3', 'w_x_logsig_4', 'py_0', 'py_1', 'py_2', 'py_3', 'py_4',\n",
      "       'py_5', 'py_6', 'py_7', 'py_8', 'py_9', 'py_10', 'py_11'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1       1\n",
       "2       1\n",
       "5       1\n",
       "8       1\n",
       "11      0\n",
       "       ..\n",
       "3843    0\n",
       "3844    0\n",
       "3846    1\n",
       "3847    1\n",
       "3849    0\n",
       "Name: Class, Length: 1663, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clasificación para detección de deficiencia hidrica\n",
    "data=mDF\n",
    "data=mDF[(data['Class']=='Control')|\\\n",
    "          #(data['Y']=='K_Control')|\\\n",
    "          #(data['Y']=='N_Control')|\\\n",
    "          #(data['Y']=='P_Control')|\\\n",
    "          (data['Class']=='H50%')\\\n",
    "           #(data['Y']=='H75%')\\\n",
    "         ]\n",
    "#X=data[list(data.columns[1:7]) + list(data.columns[16:])]\n",
    "X=data[list(data.columns[0:-3])]\n",
    "print(X.columns)\n",
    "Yo=((data['Class']=='Control') |\\\n",
    "    (data['Class']=='K_Control') |\\\n",
    "    (data['Class']=='N_Control') |\\\n",
    "    (data['Class']=='P_Control')).astype(int)\n",
    "Yo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583299c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      " R^2_train:  0.6556390977443609\n",
      " R^2_test:  0.6606606606606606\n",
      "2\n",
      " R^2_train:  0.6609022556390978\n",
      " R^2_test:  0.6576576576576577\n",
      "3\n",
      " R^2_train:  0.6864661654135338\n",
      " R^2_test:  0.6726726726726727\n",
      "4\n",
      " R^2_train:  0.7218045112781954\n",
      " R^2_test:  0.6546546546546547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "GR=np.arange(1,7)\n",
    "def LR_GR(GR,X,Y):\n",
    "    polynomial_features = PolynomialFeatures(degree=GR)\n",
    "    r=polynomial_features.fit_transform(X[:,:])\n",
    "    #Xco=np.hstack((r,np.array(X[:,6:])))\n",
    "    Xco=r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xco, Y, random_state=20,train_size=0.8)\n",
    "    Lr1=LogisticRegression(max_iter=90000000000,C=0.005509999999999979)\n",
    "    #Lr1=LogisticRegression(max_iter=90000000000)\n",
    "    Lr1.fit(X_train,y_train)\n",
    "    pr_tr=Lr1.score(X_train,y_train)\n",
    "    pr_ts=Lr1.score(X_test,y_test)\n",
    "    print(GR)\n",
    "    print(' R^2_train: ', pr_tr)\n",
    "    print(' R^2_test: ', pr_ts)\n",
    "    return Lr1,GR,pr_tr,pr_ts\n",
    "v_LR_GR=np.vectorize(LR_GR,signature='(),(j,k),(l)->(),(),(),()')\n",
    "LR,GR,pr_tr2,pr_ts2=v_LR_GR(GR,X,np.array(Yo))\n",
    "\n",
    "plt.plot(GR,pr_tr2, 'ro--')\n",
    "plt.plot(GR,pr_ts2, 'bo--')\n",
    "plt.show()\n",
    "\n",
    "plt.bar(np.arange(LR[np.argmax(pr_ts2)].coef_[0].shape[0]),np.abs(LR[np.argmax(pr_ts2)].coef_[0]))\n",
    "plt.show()\n",
    "\n",
    "#plt.bar(np.arange(LR[0].coef_[0].shape[0]),np.abs(LR[0].coef_[0].sort()))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fd1f8a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.00501\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005019999999999999\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6936936936936937\n",
      "0.005029999999999999\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0050399999999999985\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6936936936936937\n",
      "0.005049999999999998\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005059999999999998\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005069999999999997\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005079999999999997\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6936936936936937\n",
      "0.0050899999999999964\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005099999999999996\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6936936936936937\n",
      "0.005109999999999996\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005119999999999995\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005129999999999995\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6906906906906907\n",
      "0.005139999999999994\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005149999999999994\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005159999999999994\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005169999999999993\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6936936936936937\n",
      "0.005179999999999993\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005189999999999992\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005199999999999992\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0052099999999999915\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005219999999999991\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005229999999999991\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.00523999999999999\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.00524999999999999\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0052599999999999895\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005269999999999989\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005279999999999989\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005289999999999988\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6936936936936937\n",
      "0.005299999999999988\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0053099999999999875\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005319999999999987\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005329999999999987\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005339999999999986\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005349999999999986\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0053599999999999854\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6936936936936937\n",
      "0.005369999999999985\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005379999999999985\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005389999999999984\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005399999999999984\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005409999999999983\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6876876876876877\n",
      "0.005419999999999983\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6936936936936937\n",
      "0.005429999999999983\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005439999999999982\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005449999999999982\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005459999999999981\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005469999999999981\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.0054799999999999805\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6996996996996997\n",
      "0.00548999999999998\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.00549999999999998\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005509999999999979\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.7027027027027027\n",
      "0.005519999999999979\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6996996996996997\n",
      "0.0055299999999999785\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005539999999999978\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005549999999999978\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005559999999999977\n",
      " R^2_train:  0.7609022556390977\n",
      " R^2_test:  0.6936936936936937\n",
      "0.005569999999999977\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0055799999999999765\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005589999999999976\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.7027027027027027\n",
      "0.005599999999999976\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005609999999999975\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.7027027027027027\n",
      "0.005619999999999975\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.7027027027027027\n",
      "0.0056299999999999744\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005639999999999974\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005649999999999974\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005659999999999973\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005669999999999973\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005679999999999972\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005689999999999972\n",
      " R^2_train:  0.7609022556390977\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005699999999999972\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005709999999999971\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.7027027027027027\n",
      "0.005719999999999971\n",
      " R^2_train:  0.7609022556390977\n",
      " R^2_test:  0.7027027027027027\n",
      "0.00572999999999997\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.7027027027027027\n",
      "0.00573999999999997\n",
      " R^2_train:  0.7609022556390977\n",
      " R^2_test:  0.7027027027027027\n",
      "0.0057499999999999695\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.7027027027027027\n",
      "0.005759999999999969\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005769999999999969\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005779999999999968\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.7027027027027027\n",
      "0.005789999999999968\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0057999999999999675\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005809999999999967\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.7027027027027027\n",
      "0.005819999999999967\n",
      " R^2_train:  0.7609022556390977\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005829999999999966\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005839999999999966\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.7027027027027027\n",
      "0.0058499999999999655\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005859999999999965\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.7027027027027027\n",
      "0.005869999999999965\n",
      " R^2_train:  0.7609022556390977\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005879999999999964\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005889999999999964\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005899999999999963\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005909999999999963\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.7027027027027027\n",
      "0.005919999999999963\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005929999999999962\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005939999999999962\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.7027027027027027\n",
      "0.005949999999999961\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6996996996996997\n",
      "0.005959999999999961\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.7027027027027027\n",
      "0.005969999999999961\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6996996996996997\n",
      "0.00597999999999996\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6996996996996997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00598999999999996\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.005999999999999959\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6996996996996997\n",
      "0.006009999999999959\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0060199999999999585\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.7027027027027027\n",
      "0.006029999999999958\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006039999999999958\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006049999999999957\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6996996996996997\n",
      "0.006059999999999957\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0060699999999999565\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.006079999999999956\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6996996996996997\n",
      "0.006089999999999956\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006099999999999955\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.006109999999999955\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6996996996996997\n",
      "0.0061199999999999545\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006129999999999954\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006139999999999954\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006149999999999953\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006159999999999953\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006169999999999952\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006179999999999952\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006189999999999952\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006199999999999951\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006209999999999951\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.00621999999999995\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.00622999999999995\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6996996996996997\n",
      "0.00623999999999995\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006249999999999949\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006259999999999949\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006269999999999948\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6996996996996997\n",
      "0.006279999999999948\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0062899999999999475\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006299999999999947\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6996996996996997\n",
      "0.006309999999999947\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006319999999999946\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006329999999999946\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0063399999999999455\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006349999999999945\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.006359999999999945\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006369999999999944\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006379999999999944\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.0063899999999999435\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006399999999999943\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006409999999999943\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006419999999999942\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006429999999999942\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006439999999999941\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006449999999999941\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006459999999999941\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.00646999999999994\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.00647999999999994\n",
      " R^2_train:  0.7654135338345864\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006489999999999939\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.006499999999999939\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.006509999999999939\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006519999999999938\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006529999999999938\n",
      " R^2_train:  0.7654135338345864\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006539999999999937\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006549999999999937\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0065599999999999365\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006569999999999936\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006579999999999936\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006589999999999935\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006599999999999935\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0066099999999999345\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006619999999999934\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006629999999999934\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006639999999999933\n",
      " R^2_train:  0.7616541353383459\n",
      " R^2_test:  0.6996996996996997\n",
      "0.006649999999999933\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0066599999999999325\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6996996996996997\n",
      "0.006669999999999932\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006679999999999932\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006689999999999931\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006699999999999931\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.00670999999999993\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.00671999999999993\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.00672999999999993\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006739999999999929\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006749999999999929\n",
      " R^2_train:  0.7631578947368421\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006759999999999928\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006769999999999928\n",
      " R^2_train:  0.762406015037594\n",
      " R^2_test:  0.6996996996996997\n",
      "0.006779999999999928\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006789999999999927\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006799999999999927\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006809999999999926\n",
      " R^2_train:  0.7654135338345864\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006819999999999926\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0068299999999999255\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006839999999999925\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006849999999999925\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006859999999999924\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6996996996996997\n",
      "0.006869999999999924\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0068799999999999235\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006889999999999923\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006899999999999923\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006909999999999922\n",
      " R^2_train:  0.7654135338345864\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006919999999999922\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.0069299999999999215\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006939999999999921\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006949999999999921\n",
      " R^2_train:  0.7646616541353384\n",
      " R^2_test:  0.6966966966966966\n",
      "0.00695999999999992\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00696999999999992\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006979999999999919\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n",
      "0.006989999999999919\n",
      " R^2_train:  0.7639097744360902\n",
      " R^2_test:  0.6966966966966966\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "polynomial_features = PolynomialFeatures(degree=5)\n",
    "Xc=polynomial_features.fit_transform(X[X.columns[:6]])\n",
    "Xc=np.hstack((X[X.columns[6:]],Xc))\n",
    "C=np.arange(0.005,0.007,0.00001)\n",
    "def LR_C(C,X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=20,train_size=0.8)\n",
    "    Lr1=LogisticRegression(max_iter=900000,C=C)\n",
    "    Lr1.fit(X_train,y_train)\n",
    "    pr_tr=Lr1.score(X_train,y_train)\n",
    "    pr_ts=Lr1.score(X_test,y_test)\n",
    "    print(C)\n",
    "    print(' R^2_train: ', pr_tr)\n",
    "    print(' R^2_test: ', pr_ts)\n",
    "    return Lr1,C,pr_tr,pr_ts\n",
    "v_LR_C=np.vectorize(LR_C,signature='(),(j,k),(l)->(),(),(),()')\n",
    "\n",
    "LR,C,pr_tr1,pr_ts1=v_LR_C(C,Xc,np.array(Yo))\n",
    "\n",
    "plt.plot(C,pr_tr1, 'ro--')\n",
    "plt.plot(C,pr_ts1, 'bo--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1210376",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(pr_ts1))\n",
    "C[np.argmax(pr_ts1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3347ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11818738409239794\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This PolynomialFeatures instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-144af33dee86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr_ts2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpolynomial_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolynomial_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr_ts2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[0;34m(self, input_features)\u001b[0m\n\u001b[1;32m   1669\u001b[0m         \u001b[0moutput_feature_names\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mstr\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_output_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m         \"\"\"\n\u001b[0;32m-> 1671\u001b[0;31m         \u001b[0mpowers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpowers_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m             \u001b[0minput_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'x%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpowers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpowers_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpowers_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m         combinations = self._combinations(self.n_input_features_, self.degree,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This PolynomialFeatures instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "print(np.max(np.abs(LR[np.argmax(pr_ts2)].coef_[0])))\n",
    "polynomial_features = PolynomialFeatures(degree=5)\n",
    "np.hstack((np.array(polynomial_features.get_feature_names(X.columns))))[np.abs(LR[np.argmax(pr_ts2)].coef_[0])>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf629b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z_x_mu_0</th>\n",
       "      <th>z_x_mu_1</th>\n",
       "      <th>z_x_mu_2</th>\n",
       "      <th>z_x_mu_3</th>\n",
       "      <th>z_x_mu_4</th>\n",
       "      <th>z_x_logsig_0</th>\n",
       "      <th>z_x_logsig_1</th>\n",
       "      <th>z_x_logsig_2</th>\n",
       "      <th>z_x_logsig_3</th>\n",
       "      <th>z_x_logsig_4</th>\n",
       "      <th>...</th>\n",
       "      <th>py_2</th>\n",
       "      <th>py_3</th>\n",
       "      <th>py_4</th>\n",
       "      <th>py_5</th>\n",
       "      <th>py_6</th>\n",
       "      <th>py_7</th>\n",
       "      <th>py_8</th>\n",
       "      <th>py_9</th>\n",
       "      <th>py_10</th>\n",
       "      <th>py_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.686828</td>\n",
       "      <td>-2.931506</td>\n",
       "      <td>-0.840768</td>\n",
       "      <td>-5.264722</td>\n",
       "      <td>-4.424634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083366</td>\n",
       "      <td>0.083233</td>\n",
       "      <td>0.083151</td>\n",
       "      <td>0.083339</td>\n",
       "      <td>0.083519</td>\n",
       "      <td>0.083147</td>\n",
       "      <td>0.083286</td>\n",
       "      <td>0.083396</td>\n",
       "      <td>0.083619</td>\n",
       "      <td>0.083072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.622476</td>\n",
       "      <td>-1.276294</td>\n",
       "      <td>2.713542</td>\n",
       "      <td>-1.909442</td>\n",
       "      <td>1.363258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083234</td>\n",
       "      <td>0.083286</td>\n",
       "      <td>0.083166</td>\n",
       "      <td>0.083331</td>\n",
       "      <td>0.083345</td>\n",
       "      <td>0.083367</td>\n",
       "      <td>0.083316</td>\n",
       "      <td>0.083177</td>\n",
       "      <td>0.083327</td>\n",
       "      <td>0.083345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.901968</td>\n",
       "      <td>0.122716</td>\n",
       "      <td>0.709954</td>\n",
       "      <td>1.919265</td>\n",
       "      <td>0.169823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083442</td>\n",
       "      <td>0.083265</td>\n",
       "      <td>0.083174</td>\n",
       "      <td>0.083562</td>\n",
       "      <td>0.083101</td>\n",
       "      <td>0.083340</td>\n",
       "      <td>0.083320</td>\n",
       "      <td>0.083176</td>\n",
       "      <td>0.083481</td>\n",
       "      <td>0.083392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.289033</td>\n",
       "      <td>-0.518435</td>\n",
       "      <td>1.639517</td>\n",
       "      <td>-0.491957</td>\n",
       "      <td>-1.673315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083243</td>\n",
       "      <td>0.083356</td>\n",
       "      <td>0.083377</td>\n",
       "      <td>0.083395</td>\n",
       "      <td>0.082983</td>\n",
       "      <td>0.083395</td>\n",
       "      <td>0.083422</td>\n",
       "      <td>0.083239</td>\n",
       "      <td>0.083324</td>\n",
       "      <td>0.083481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-3.128330</td>\n",
       "      <td>-1.855808</td>\n",
       "      <td>-1.656450</td>\n",
       "      <td>-0.411873</td>\n",
       "      <td>-3.484109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083347</td>\n",
       "      <td>0.083238</td>\n",
       "      <td>0.083142</td>\n",
       "      <td>0.083353</td>\n",
       "      <td>0.083481</td>\n",
       "      <td>0.083199</td>\n",
       "      <td>0.083284</td>\n",
       "      <td>0.083337</td>\n",
       "      <td>0.083557</td>\n",
       "      <td>0.083134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>0.588764</td>\n",
       "      <td>-1.831064</td>\n",
       "      <td>-1.190594</td>\n",
       "      <td>-1.911008</td>\n",
       "      <td>-4.205258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083351</td>\n",
       "      <td>0.083237</td>\n",
       "      <td>0.083147</td>\n",
       "      <td>0.083348</td>\n",
       "      <td>0.083492</td>\n",
       "      <td>0.083182</td>\n",
       "      <td>0.083286</td>\n",
       "      <td>0.083357</td>\n",
       "      <td>0.083577</td>\n",
       "      <td>0.083115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>1.754386</td>\n",
       "      <td>-0.131833</td>\n",
       "      <td>-1.643568</td>\n",
       "      <td>1.396282</td>\n",
       "      <td>-1.736647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083301</td>\n",
       "      <td>0.083258</td>\n",
       "      <td>0.083124</td>\n",
       "      <td>0.083375</td>\n",
       "      <td>0.083386</td>\n",
       "      <td>0.083321</td>\n",
       "      <td>0.083291</td>\n",
       "      <td>0.083198</td>\n",
       "      <td>0.083408</td>\n",
       "      <td>0.083287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>-7.402267</td>\n",
       "      <td>-3.770921</td>\n",
       "      <td>-2.073259</td>\n",
       "      <td>-6.986263</td>\n",
       "      <td>-4.143230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083404</td>\n",
       "      <td>0.083370</td>\n",
       "      <td>0.083003</td>\n",
       "      <td>0.083484</td>\n",
       "      <td>0.083579</td>\n",
       "      <td>0.083298</td>\n",
       "      <td>0.083013</td>\n",
       "      <td>0.083279</td>\n",
       "      <td>0.083346</td>\n",
       "      <td>0.083228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>3.481685</td>\n",
       "      <td>0.067505</td>\n",
       "      <td>1.668355</td>\n",
       "      <td>-0.666159</td>\n",
       "      <td>-0.202151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083197</td>\n",
       "      <td>0.083345</td>\n",
       "      <td>0.083340</td>\n",
       "      <td>0.083316</td>\n",
       "      <td>0.083132</td>\n",
       "      <td>0.083371</td>\n",
       "      <td>0.083403</td>\n",
       "      <td>0.083257</td>\n",
       "      <td>0.083316</td>\n",
       "      <td>0.083412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>-4.504982</td>\n",
       "      <td>-3.483152</td>\n",
       "      <td>-1.558088</td>\n",
       "      <td>-3.040207</td>\n",
       "      <td>-1.875820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083339</td>\n",
       "      <td>0.083243</td>\n",
       "      <td>0.083138</td>\n",
       "      <td>0.083356</td>\n",
       "      <td>0.083463</td>\n",
       "      <td>0.083222</td>\n",
       "      <td>0.083287</td>\n",
       "      <td>0.083311</td>\n",
       "      <td>0.083530</td>\n",
       "      <td>0.083164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1663 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      z_x_mu_0  z_x_mu_1  z_x_mu_2  z_x_mu_3  z_x_mu_4  z_x_logsig_0  \\\n",
       "1    -0.686828 -2.931506 -0.840768 -5.264722 -4.424634           0.0   \n",
       "2     0.622476 -1.276294  2.713542 -1.909442  1.363258           0.0   \n",
       "5     0.901968  0.122716  0.709954  1.919265  0.169823           0.0   \n",
       "8     4.289033 -0.518435  1.639517 -0.491957 -1.673315           0.0   \n",
       "11   -3.128330 -1.855808 -1.656450 -0.411873 -3.484109           0.0   \n",
       "...        ...       ...       ...       ...       ...           ...   \n",
       "3843  0.588764 -1.831064 -1.190594 -1.911008 -4.205258           0.0   \n",
       "3844  1.754386 -0.131833 -1.643568  1.396282 -1.736647           0.0   \n",
       "3846 -7.402267 -3.770921 -2.073259 -6.986263 -4.143230           0.0   \n",
       "3847  3.481685  0.067505  1.668355 -0.666159 -0.202151           0.0   \n",
       "3849 -4.504982 -3.483152 -1.558088 -3.040207 -1.875820           0.0   \n",
       "\n",
       "      z_x_logsig_1  z_x_logsig_2  z_x_logsig_3  z_x_logsig_4  ...      py_2  \\\n",
       "1              0.0           0.0           0.0           0.0  ...  0.083366   \n",
       "2              0.0           0.0           0.0           0.0  ...  0.083234   \n",
       "5              0.0           0.0           0.0           0.0  ...  0.083442   \n",
       "8              0.0           0.0           0.0           0.0  ...  0.083243   \n",
       "11             0.0           0.0           0.0           0.0  ...  0.083347   \n",
       "...            ...           ...           ...           ...  ...       ...   \n",
       "3843           0.0           0.0           0.0           0.0  ...  0.083351   \n",
       "3844           0.0           0.0           0.0           0.0  ...  0.083301   \n",
       "3846           0.0           0.0           0.0           0.0  ...  0.083404   \n",
       "3847           0.0           0.0           0.0           0.0  ...  0.083197   \n",
       "3849           0.0           0.0           0.0           0.0  ...  0.083339   \n",
       "\n",
       "          py_3      py_4      py_5      py_6      py_7      py_8      py_9  \\\n",
       "1     0.083233  0.083151  0.083339  0.083519  0.083147  0.083286  0.083396   \n",
       "2     0.083286  0.083166  0.083331  0.083345  0.083367  0.083316  0.083177   \n",
       "5     0.083265  0.083174  0.083562  0.083101  0.083340  0.083320  0.083176   \n",
       "8     0.083356  0.083377  0.083395  0.082983  0.083395  0.083422  0.083239   \n",
       "11    0.083238  0.083142  0.083353  0.083481  0.083199  0.083284  0.083337   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3843  0.083237  0.083147  0.083348  0.083492  0.083182  0.083286  0.083357   \n",
       "3844  0.083258  0.083124  0.083375  0.083386  0.083321  0.083291  0.083198   \n",
       "3846  0.083370  0.083003  0.083484  0.083579  0.083298  0.083013  0.083279   \n",
       "3847  0.083345  0.083340  0.083316  0.083132  0.083371  0.083403  0.083257   \n",
       "3849  0.083243  0.083138  0.083356  0.083463  0.083222  0.083287  0.083311   \n",
       "\n",
       "         py_10     py_11  \n",
       "1     0.083619  0.083072  \n",
       "2     0.083327  0.083345  \n",
       "5     0.083481  0.083392  \n",
       "8     0.083324  0.083481  \n",
       "11    0.083557  0.083134  \n",
       "...        ...       ...  \n",
       "3843  0.083577  0.083115  \n",
       "3844  0.083408  0.083287  \n",
       "3846  0.083346  0.083228  \n",
       "3847  0.083316  0.083412  \n",
       "3849  0.083530  0.083164  \n",
       "\n",
       "[1663 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paltas",
   "language": "python",
   "name": "paltas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
