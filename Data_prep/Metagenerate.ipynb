{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0826ae7a-f225-4520-881f-00cef2dac881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "#import skimage\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import glob\n",
    "from skimage import io\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "from Custom_dataloader import *\n",
    "import matplotlib.pyplot as plt\n",
    "from os import stat\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.color import rgb2gray\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e07239d2-d961-44a0-b677-495cf7bffa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_rec(bmask, small=True,fn = cv2.contourArea):\n",
    "    bmask = bmask.astype(np.uint8)\n",
    "    mass = np.zeros_like(bmask, dtype=np.uint8)\n",
    "    _,contours ,_ =cv2.findContours(bmask,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    rc = []\n",
    "    for i in contours:\n",
    "        epsilon = 0.5*cv2.arcLength(i,True)\n",
    "\n",
    "        if cv2.contourArea(i)>8000:\n",
    "            vv = cv2.boundingRect(i)\n",
    "            vva = vv[2]*vv[3]\n",
    "            if cv2.contourArea(i)/vva >=0.7:\n",
    "                rc.append(i)\n",
    "    rc = sorted(rc, key=fn)\n",
    "    #print(len(rc))\n",
    "    if small:\n",
    "        cv2.fillPoly(mass, pts = [rc[0]], color=255)\n",
    "    else:\n",
    "        cv2.fillPoly(mass, pts = [rc[-1]], color=255)\n",
    "    _,yy,_,hy = cv2.boundingRect(mass)\n",
    "    \n",
    "    return mass.astype(np.bool_), yy, hy\n",
    "\n",
    "def get_clothe_masks(img):\n",
    "    b_mask = ((img[:, :, 0]<20) & (img[:, :, 1]<20) & (img[:, :, 2]<20))\n",
    "    b_mask, yb, hb = return_rec(b_mask)\n",
    "    g_mask = (abs(img[:,:,2]-img[:,:,0])<14) & (img[:,:,2]>45)\n",
    "    g_mask, yg, hg = return_rec(g_mask)\n",
    "    y = min(yb, yg)\n",
    "    h = max(hb, hg)\n",
    "    ra = img.copy()\n",
    "    ra[y+h+100::,:,2]=0\n",
    "    ra[max(y-100,0)::-1,:,2]=0\n",
    "    #plt.imshow(ra[:,:,::-1])\n",
    "    r_mask = ((ra[:, :, 2]>105) & (ra[:, :, 1]<60))\n",
    "    r_mask,_,_ = return_rec(r_mask, small=False)\n",
    "    return r_mask, g_mask, b_mask\n",
    "\n",
    "def reg(rgb_img, nir_img):\n",
    "    ## Registration\n",
    "    rgb_ = cv2.resize(rgb_img, (4000, 3000))\n",
    "    rgb_ = cv2.cvtColor(rgb_, cv2.COLOR_BGR2GRAY) \n",
    "    \n",
    "    nir_ = cv2.resize(nir_img, (4000, 3000))\n",
    "    nir_ = nir_[:, :, 0]\n",
    "    \n",
    "    #akaze = cv2.xfeatures2d.SIFT_create()\n",
    "    akaze = cv2.xfeatures2d.SURF_create() #python version mismatch\n",
    "    kp1, des1 = akaze.detectAndCompute(rgb_, None)\n",
    "    kp2, des2 = akaze.detectAndCompute(nir_, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_L1)\n",
    "    matches = bf.knnMatch(des1, des2, k = 2)\n",
    "    \n",
    "    good_matches = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            good_matches.append([m])\n",
    "    \n",
    "    ref_matched_kpts = np.float32([kp1[m[0].queryIdx].pt for m in good_matches])\n",
    "    sensed_matched_kpts = np.float32([kp2[m[0].trainIdx].pt for m in good_matches])\n",
    "    \n",
    "    H, status = cv2.findHomography(sensed_matched_kpts, ref_matched_kpts, cv2.RANSAC,80.0)\n",
    "    nir_img = cv2.warpPerspective(nir_img, H, (rgb_img.shape[1], rgb_img.shape[0]))\n",
    "    return nir_img\n",
    "def compute_ndvi(rgb_img, nir_img, mask, statistic=True):\n",
    "    ## Registration\n",
    "    rgb_ = cv2.resize(rgb_img, (4000, 3000))\n",
    "    rgb_ = cv2.cvtColor(rgb_, cv2.COLOR_BGR2GRAY) \n",
    "    \n",
    "    nir_ = cv2.resize(nir_img, (4000, 3000))\n",
    "    nir_ = nir_[:, :, 0]\n",
    "    \n",
    "    akaze = cv2.xfeatures2d.SURF_create()\n",
    "    \n",
    "    kp1, des1 = akaze.detectAndCompute(rgb_, None)\n",
    "    kp2, des2 = akaze.detectAndCompute(nir_, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_L1)\n",
    "    matches = bf.knnMatch(des1, des2, k = 2)\n",
    "    \n",
    "    good_matches = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            good_matches.append([m])\n",
    "    \n",
    "    ref_matched_kpts = np.float32([kp1[m[0].queryIdx].pt for m in good_matches])\n",
    "    sensed_matched_kpts = np.float32([kp2[m[0].trainIdx].pt for m in good_matches])\n",
    "    \n",
    "    H, status = cv2.findHomography(sensed_matched_kpts, ref_matched_kpts, cv2.RANSAC,80.0)\n",
    "    nir_img = cv2.warpPerspective(nir_img, H, (rgb_img.shape[1], rgb_img.shape[0]))\n",
    "    \n",
    "    ##Adjustment\n",
    "    \n",
    "    #====================SKIMAGE VERSION\n",
    "    #rgb_img = rgb_img[::-1]\n",
    "    #nir_img = nir_img[::-1]\n",
    "    #=================================\n",
    "    rgb_img = rgb_img.astype(np.float64)\n",
    "    nir_img = nir_img.astype(np.float64)\n",
    "    RR = np.array([[1.377, -0.182, -0.061],\n",
    "          [-0.199, 1.420, -0.329],\n",
    "          [-0.034, -0.110, 1.150]])\n",
    "    RN = np.array([[-0.956, 0., 1.],\n",
    "          [2.426, 0., -0.341],\n",
    "          [0., 1., 0.]])\n",
    "    maskn = ((nir_img[:,:,0]!=0)&(nir_img[:,:,1]!=0)&(nir_img[:,:,2]!=0)).astype(np.bool_)\n",
    "    rgb_img = np.matmul(rgb_img, RR.T)\n",
    "    nir_img = np.matmul(nir_img, RN.T)\n",
    "    NDVI = (2.7*nir_img[:, :, 1]-rgb_img[:, :, 2])/(2.7*nir_img[:, :, 1]+rgb_img[:, :, 2])\n",
    "    mask &= maskn\n",
    "    ##Mean STD calculation\n",
    "    #plt.imshow(NDVI)\n",
    "    \n",
    "    if not(statistic):\n",
    "        #imout = np.zeros_like(NDVI)\n",
    "        #imout[mask] = NDVI[mask]\n",
    "        #return imout\n",
    "        return cv2.bitwise_and(NDVI, NDVI, mask=mask)\n",
    "    else:\n",
    "        mask = mask.astype(bool)\n",
    "        mndvi = NDVI[mask]\n",
    "        return [mndvi.mean(), mndvi.std()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34de9401-f78b-483f-823c-44db755c1c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ndvi_desc():\n",
    "    \"\"\"Compute NDVI from RGB and NIR image \n",
    "    \n",
    "    Args:\n",
    "        statistic(boolean): Return either mean and std\n",
    "        or masked NDVI image\n",
    "        \n",
    "    output:\n",
    "        NDVI mean and std\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, statistic_ = False):\n",
    "        self.statistic = statistic_\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        rgb, nir, mask, landmarks = sample['SenteraRGB'],\\\n",
    "            sample['SenteraNIR'], sample['SenteraMASK'],\\\n",
    "                 sample['landmarks']\n",
    "        mask.astype(np.bool_)\n",
    "        rgb = rgb[::-1]\n",
    "        nir = nir[::-1]\n",
    "        \n",
    "        if self.statistic:\n",
    "            mean, std = compute_ndvi(rgb,nir, mask)\n",
    "            return{'SenteraNDVI': {'mean': mean, 'std': std}, 'landmarks': landmarks, 'Date':sample['Date']}\n",
    "        else:\n",
    "            ndvi = compute_ndvi(rgb,nir, mask, statistic=False)\n",
    "            return{'SenteraNDVI': ndvi, 'landmarks': landmarks, 'Date':sample['Date']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16be9ded-f49a-47ab-be60-c65b6fa7da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class texture_desc():\n",
    "    \"\"\"\n",
    "    Co-ocupance matrix analysis either ndvi(-1, 1) or rgb(0, 255)\n",
    "    Working only in sentera(to be fixed)\n",
    "    \"\"\"\n",
    "    def __init__(self,descriptor='correlation' ,from_rgb=True):\n",
    "        self.descriptor = descriptor\n",
    "        self.from_rgb = from_rgb\n",
    "        \n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        img = np.zeros_like(sample['SenteraRGB'])\n",
    "        if self.from_rgb:\n",
    "            img = sample['SenteraRGB']\n",
    "            \n",
    "            img = rgb2gray(img)\n",
    "            img = (img*255).astype(np.uint8)\n",
    "        else:\n",
    "            rgb, nir= sample['SenteraRGB'], sample['SenteraNIR']\n",
    "            fmask = np.ones_like(rgb)[:,:,0]\n",
    "            fmask = fmask.astype(np.bool_)\n",
    "            rgb = rgb[::-1]\n",
    "            nir = nir[::-1]\n",
    "            ndvi = compute_ndvi(rgb,nir, fmask, statistic=False)\n",
    "            img = ((ndvi+1)*255/2).astype(np.uint8)\n",
    "        \n",
    "        mask = sample['SenteraMASK']\n",
    "        mask = mask.astype(bool)\n",
    "        \n",
    "        horizontal_indicies = np.where(np.any(mask, axis=0))[0]\n",
    "        vertical_indicies = np.where(np.any(mask, axis=1))[0]\n",
    "        x1, x2 = horizontal_indicies[[0, -1]]\n",
    "        y1, y2 = vertical_indicies[[0, -1]]\n",
    "        \n",
    "        img = img[y1:y2, x1:x2]\n",
    "        #img = img.astype(np.uint8)\n",
    "            \n",
    "        glcm = greycomatrix(img, distances=[15, 30, 50], angles=[0, np.pi/2], levels=256)\n",
    "        \n",
    "        return {('Sentera'+self.descriptor): greycoprops(glcm, self.descriptor),'image':img, 'landmarks': sample['landmarks'], 'Date':sample['Date']}\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd08dee-14c5-45c5-8f1d-9c66fdd6ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB=\"/run/user/1000/gvfs/afp-volume:host=MyCloudPR4100.local,user=admin,volume=Paltas_DataBase/Data_Base_v2\"\n",
    "\n",
    "d_t = transforms.Compose([ndvi_desc(statistic_=True)])\n",
    "datab=Dataset_direct(root_dir=DB,ImType=['SenteraRGB', 'SenteraNIR', 'SenteraMASK'],Intersec=False, transform=d_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cabb1ff-7abf-4475-b492-eff1d1391ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SenteraNDVI': {'mean': 0.8910017212308047, 'std': 0.06402366357584308},\n",
       " 'landmarks': array(['N_Control'], dtype='<U13'),\n",
       " 'Date': '11_junio_1'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datab[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec6b003f-4b5b-493a-b652-0566473b6f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##NDVI MEAN STD\n",
    "out = []\n",
    "for i, item in enumerate(datab):\n",
    "    out.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0212a1fd-61f5-4c99-b3c2-90d4c14e4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = np.array(out)\n",
    "np.save('ndvistats.npy', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576db510-aefd-4663-9ace-bca3f572e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB=\"/run/user/1000/gvfs/afp-volume:host=MyCloudPR4100.local,volume=Paltas_DataBase/Data_Base_v2\"\n",
    "\n",
    "d_t = transforms.Compose([texture_desc('correlation')])\n",
    "datab=Dataset_direct(root_dir=DB,ImType=['SenteraRGB', 'SenteraMASK'],Intersec=False, transform=d_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "569b5bea-c6bb-4d04-bfed-341cdd607b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Senteracorrelation': array([[0.59604274, 0.63928618],\n",
       "        [0.43609427, 0.44697792],\n",
       "        [0.38503617, 0.38275879]]),\n",
       " 'image': array([[43, 44, 45, ..., 41, 40, 38],\n",
       "        [43, 45, 46, ..., 42, 42, 39],\n",
       "        [44, 47, 48, ..., 43, 43, 40],\n",
       "        ...,\n",
       "        [56, 54, 54, ..., 48, 48, 48],\n",
       "        [56, 54, 54, ..., 47, 47, 46],\n",
       "        [54, 53, 53, ..., 47, 46, 45]], dtype=uint8),\n",
       " 'landmarks': array(['N_Control'], dtype='<U13'),\n",
       " 'Date': '11_junio_1'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datab[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36225a94-718a-4496-a57a-c05c1e5f4745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3284it [33:21,  1.54it/s]"
     ]
    }
   ],
   "source": [
    "out = {}\n",
    "for i, item in enumerate(tqdm(datab)):\n",
    "    out.update({i:item})\n",
    "fil = open('senterargbcorrelation.pkl', 'wb')\n",
    "pickle.dump(out, fil)\n",
    "fil.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed7c76c-da88-4ba0-87d4-430ac72811ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8657d600-7ec2-435d-8108-3e7848fce5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB=\"/run/user/1000/gvfs/afp-volume:host=MyCloudPR4100.local,user=admin,volume=Paltas_DataBase/Data_Base_v2\"\n",
    "\n",
    "d_t = transforms.Compose([texture_desc('energy')])\n",
    "datab=Dataset_direct(root_dir=DB,ImType=['SenteraRGB', 'SenteraMASK'],Intersec=False, transform=d_t)\n",
    "out = []\n",
    "for i, item in enumerate(datab):\n",
    "    out.append(item)\n",
    "out = np.array(out)\n",
    "np.save('senterargbenergy.npy', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7b9222-e961-40eb-918b-edac1c98120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB=\"/run/user/1000/gvfs/afp-volume:host=MyCloudPR4100.local,user=admin,volume=Paltas_DataBase/Data_Base_v2\"\n",
    "\n",
    "d_t = transforms.Compose([texture_desc('ASM')])\n",
    "datab=Dataset_direct(root_dir=DB,ImType=['SenteraRGB', 'SenteraMASK'],Intersec=False, transform=d_t)\n",
    "out = []\n",
    "for i, item in enumerate(datab):\n",
    "    out.append(item)\n",
    "out = np.array(out)\n",
    "np.save('senterargbasm.npy', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1423a783-97c6-4b3c-a03e-aa7c3a2e5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB=\"/run/user/1000/gvfs/afp-volume:host=MyCloudPR4100.local,user=admin,volume=Paltas_DataBase/Data_Base_v2\"\n",
    "\n",
    "d_t = transforms.Compose([texture_desc('homogeneity')])\n",
    "datab=Dataset_direct(root_dir=DB,ImType=['SenteraRGB', 'SenteraMASK'],Intersec=False, transform=d_t)\n",
    "out = []\n",
    "for i, item in enumerate(datab):\n",
    "    out.append(item)\n",
    "out = np.array(out)\n",
    "np.save('senterargbhomogeneity.npy', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd5b53-b85e-4307-a81a-a58d9d19baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB=\"/run/user/1000/gvfs/afp-volume:host=MyCloudPR4100.local,user=admin,volume=Paltas_DataBase/Data_Base_v2\"\n",
    "\n",
    "d_t = transforms.Compose([texture_desc('dissimilarity')])\n",
    "datab=Dataset_direct(root_dir=DB,ImType=['SenteraRGB', 'SenteraMASK'],Intersec=False, transform=d_t)\n",
    "out = []\n",
    "for i, item in enumerate(datab):\n",
    "    out.append(item)\n",
    "out = np.array(out)\n",
    "np.save('senterargbdissimilarity.npy', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e0852-f8b2-4df0-9ac6-aebdba5feefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB=\"/run/user/1000/gvfs/afp-volume:host=MyCloudPR4100.local,user=admin,volume=Paltas_DataBase/Data_Base_v2\"\n",
    "\n",
    "d_t = transforms.Compose([texture_desc('contrast')])\n",
    "datab=Dataset_direct(root_dir=DB,ImType=['SenteraRGB', 'SenteraMASK'],Intersec=False, transform=d_t)\n",
    "out = []\n",
    "for i, item in enumerate(datab):\n",
    "    out.append(item)\n",
    "out = np.array(out)\n",
    "np.save('senterargbcontrast.npy', out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
