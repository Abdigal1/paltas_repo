{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8b3981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LIARPI\\Anaconda3\\envs\\paltas\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\LIARPI\\Anaconda3\\envs\\paltas\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import fire as fire\n",
    "from B_VAE.VAE_meta import b_encodeco\n",
    "from Train_utils import train_utils\n",
    "from B_VAE.Utils_imp_VAE import loss_fn\n",
    "from Train_utils.train_utils import train,test,K_fold_train\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(\"..\",\"Data_prep\"))\n",
    "from torchvision import transforms\n",
    "from Custom_dataloader import *\n",
    "from Transforms import phantom_segmentation\n",
    "from Transforms import multi_image_resize\n",
    "from Transforms import multi_ToTensor\n",
    "from Transforms import output_transform\n",
    "from Transforms import pos_fly_transform\n",
    "from Transforms import concatenate_non_uniform_transform\n",
    "from Transforms import only_tensor_transform\n",
    "from Transforms import rgb_normalize\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f797723",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB=\"/run/user/1000/gvfs/afp-volume:host=MyCloudPR4100.local,user=aorus_1,volume=Paltas_DataBase/Data_Base_v2\"\n",
    "DB=\"//MYCLOUDPR4100/Paltas_DataBase/Data_Base_v2\"\n",
    "\n",
    "d_tt=transforms.Compose([\n",
    "        phantom_segmentation(False,non_uniform_input=True),\n",
    "        rgb_normalize(ImType=['PhantomRGB']),\n",
    "        multi_image_resize(ImType=['PhantomRGB'],size=(20,20)),\n",
    "        pos_fly_transform(),\n",
    "        concatenate_non_uniform_transform(),\n",
    "        multi_ToTensor(ImType=['PhantomRGB']),\n",
    "        only_tensor_transform(),\n",
    "        #output_transform()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a19977",
   "metadata": {},
   "outputs": [],
   "source": [
    "datab=Dataset_direct(root_dir=DB,ImType=['PhantomRGB'],Intersec=False,transform=d_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=datab[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=b_encodeco(\n",
    "                 image_dim=int(20),\n",
    "                 image_channels=3,\n",
    "                 non_uniform_dim=32,\n",
    "                 repr_sizes=[2,4],\n",
    "                 pre_layer_sizes=[500],\n",
    "                 layer_sizes=[300],\n",
    "                 pre_output=400,\n",
    "                 latent_space_size=20,\n",
    "                 conv_kernel_size=5,\n",
    "                 activators=[nn.Tanh(),nn.ReLU()],\n",
    "                 conv_pooling=False,\n",
    "                 conv_batch_norm=True,\n",
    "                 NN_batch_norm=True,\n",
    "                 stride=1,\n",
    "                device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd108f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d397c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train=torch.utils.data.DataLoader(datab,batch_size=1,shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb77923",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader_train:\n",
    "    #print(idx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4496b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1,z2,mu,sig=model.forward_non_uniform(batch['PhantomRGB'],batch['Non_uniform_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81455439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0acfc691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2297, 2.9408, 0.5337, 0.2866, 2.5080, 1.8850, 2.8411, 0.9672]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.from_numpy(np.random.uniform(0,4,(1,3)))\n",
    "b=torch.from_numpy(np.random.uniform(0,4,(1,5)))\n",
    "torch.concat((a,b),dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c51d959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1412, 0.1456, 0.1535, 0.1591, 0.1575, 0.1326, 0.1017, 0.1154, 0.1428,\n",
      "         0.1549, 0.1302, 0.1060, 0.1348, 0.1363, 0.1577, 0.1723, 0.1770, 0.1579,\n",
      "         0.1184, 0.1088, 0.1275, 0.1451, 0.1412, 0.1229, 0.1325, 0.1303, 0.1531,\n",
      "         0.1663, 0.1806, 0.1676, 0.1389, 0.1200, 0.1164, 0.1240, 0.1364, 0.1356,\n",
      "         0.1536, 0.1431, 0.1432, 0.1411, 0.1588, 0.1681, 0.1624, 0.1354, 0.1186,\n",
      "         0.1158, 0.1350, 0.1394, 0.1660, 0.1634, 0.1542, 0.1340, 0.1407, 0.1559,\n",
      "         0.1711, 0.1535, 0.1345, 0.1236, 0.1287, 0.1328, 0.1494, 0.1635, 0.1652,\n",
      "         0.1424, 0.1270, 0.1376, 0.1642, 0.1594, 0.1462, 0.1402, 0.1411, 0.1328,\n",
      "         0.1358, 0.1613, 0.1635, 0.1447, 0.1278, 0.1340, 0.1474, 0.1571, 0.1591,\n",
      "         0.1659, 0.1563, 0.1427, 0.1422, 0.1529, 0.1505, 0.1542, 0.1524, 0.1495,\n",
      "         0.1331, 0.1469, 0.1659, 0.1720, 0.1632, 0.1537, 0.1532, 0.1600, 0.1502,\n",
      "         0.1541, 0.1609, 0.1615, 0.1557, 0.1583, 0.1564, 0.1668, 0.1768, 0.1764,\n",
      "         0.1559, 0.1598, 0.1559, 0.1530, 0.1585, 0.1723, 0.1724, 0.1550, 0.1457,\n",
      "         0.1626, 0.1784, 0.1775, 0.1623, 0.1555, 0.1554, 0.1594, 0.1532, 0.1635,\n",
      "         0.1756, 0.1694, 0.1500, 0.1480, 0.1512, 0.1706, 0.1635, 0.1462, 0.1493,\n",
      "         0.1489, 0.1304, 0.1417, 0.1650, 0.1653, 0.1411, 0.1357, 0.1344, 0.1610,\n",
      "         0.0428, 0.0649, 0.0868, 0.0704, 0.0510, 0.0477, 0.0469, 0.0375, 0.0461,\n",
      "         0.0546, 0.0539, 0.0331, 0.0487, 0.0623, 0.0834, 0.0756, 0.0603, 0.0606,\n",
      "         0.0560, 0.0297, 0.0177, 0.0343, 0.0630, 0.0498, 0.0518, 0.0700, 0.0752,\n",
      "         0.0688, 0.0677, 0.0751, 0.0699, 0.0422, 0.0166, 0.0196, 0.0546, 0.0668,\n",
      "         0.0685, 0.0671, 0.0552, 0.0450, 0.0533, 0.0824, 0.0720, 0.0498, 0.0348,\n",
      "         0.0338, 0.0342, 0.0517, 0.0929, 0.0835, 0.0533, 0.0387, 0.0386, 0.0670,\n",
      "         0.0679, 0.0645, 0.0512, 0.0397, 0.0291, 0.0452, 0.0890, 0.0785, 0.0588,\n",
      "         0.0651, 0.0615, 0.0614, 0.0661, 0.0783, 0.0736, 0.0548, 0.0345, 0.0430,\n",
      "         0.0845, 0.0671, 0.0638, 0.0678, 0.0777, 0.0692, 0.0654, 0.0760, 0.0863,\n",
      "         0.0821, 0.0690, 0.0562, 0.0801, 0.0564, 0.0698, 0.0866, 0.0916, 0.0776,\n",
      "         0.0669, 0.0733, 0.0858, 0.0937, 0.0941, 0.0838, 0.0736, 0.0616, 0.0658,\n",
      "         0.0771, 0.0789, 0.0836, 0.0742, 0.0626, 0.0628, 0.0809, 0.0853, 0.0827,\n",
      "         0.0678, 0.0626, 0.0571, 0.0670, 0.0684, 0.0667, 0.0541, 0.0455, 0.0499,\n",
      "         0.0593, 0.0541, 0.0467, 0.0390, 0.0338, 0.0393, 0.0437, 0.0369, 0.0228,\n",
      "         0.0255, 0.0418, 0.0425, 0.0238, 0.0115, 0.0059, 0.0289, 0.0350, 0.0306,\n",
      "         0.0255, 0.0022, 0.0000, 0.0176, 0.0358, 0.0334, 0.0042, 0.0000, 0.0103,\n",
      "         0.1264, 0.0970, 0.0875, 0.1069, 0.1238, 0.1335, 0.1236, 0.1198, 0.1134,\n",
      "         0.0878, 0.0634, 0.0592, 0.1377, 0.1103, 0.1075, 0.1165, 0.1166, 0.1217,\n",
      "         0.1219, 0.1346, 0.1296, 0.1039, 0.0820, 0.0714, 0.1298, 0.1249, 0.1283,\n",
      "         0.1328, 0.1244, 0.1139, 0.1248, 0.1400, 0.1372, 0.1285, 0.1099, 0.0945,\n",
      "         0.1183, 0.1306, 0.1333, 0.1270, 0.1141, 0.1127, 0.1170, 0.1281, 0.1347,\n",
      "         0.1392, 0.1325, 0.1206, 0.1287, 0.1408, 0.1436, 0.1386, 0.1246, 0.1183,\n",
      "         0.1203, 0.1250, 0.1345, 0.1450, 0.1500, 0.1430, 0.1331, 0.1420, 0.1443,\n",
      "         0.1317, 0.1252, 0.1295, 0.1354, 0.1288, 0.1303, 0.1415, 0.1551, 0.1487,\n",
      "         0.1428, 0.1470, 0.1447, 0.1208, 0.1225, 0.1246, 0.1355, 0.1365, 0.1425,\n",
      "         0.1483, 0.1549, 0.1527, 0.1491, 0.1530, 0.1508, 0.1334, 0.1307, 0.1400,\n",
      "         0.1467, 0.1527, 0.1498, 0.1390, 0.1466, 0.1556, 0.1619, 0.1591, 0.1397,\n",
      "         0.1336, 0.1316, 0.1467, 0.1542, 0.1484, 0.1392, 0.1360, 0.1427, 0.1528,\n",
      "         0.1588, 0.1453, 0.1319, 0.1401, 0.1513, 0.1556, 0.1468, 0.1335, 0.1348,\n",
      "         0.1432, 0.1510, 0.1388, 0.1476, 0.1252, 0.1241, 0.1356, 0.1526, 0.1428,\n",
      "         0.1399, 0.1277, 0.1258, 0.1360, 0.1433, 0.1290, 0.1309, 0.1133, 0.1283,\n",
      "         0.1419, 0.1549, 0.1496, 0.1338, 0.1141, 0.1183, 0.1393, 0.1411, 0.1273,\n",
      "         0.0183, 0.0000, 0.0000, 0.0000, 0.0000, 0.0060, 0.0181, 0.0278, 0.0175,\n",
      "         0.0000, 0.0000, 0.0000, 0.0166, 0.0062, 0.0000, 0.0016, 0.0057, 0.0144,\n",
      "         0.0205, 0.0421, 0.0476, 0.0142, 0.0000, 0.0000, 0.0257, 0.0083, 0.0062,\n",
      "         0.0076, 0.0032, 0.0075, 0.0150, 0.0348, 0.0498, 0.0370, 0.0027, 0.0000,\n",
      "         0.0406, 0.0205, 0.0202, 0.0251, 0.0165, 0.0098, 0.0099, 0.0236, 0.0347,\n",
      "         0.0313, 0.0241, 0.0088, 0.0368, 0.0312, 0.0324, 0.0341, 0.0336, 0.0163,\n",
      "         0.0194, 0.0236, 0.0268, 0.0268, 0.0283, 0.0199, 0.0367, 0.0410, 0.0442,\n",
      "         0.0252, 0.0209, 0.0235, 0.0221, 0.0192, 0.0240, 0.0354, 0.0433, 0.0314,\n",
      "         0.0452, 0.0477, 0.0412, 0.0286, 0.0187, 0.0247, 0.0292, 0.0275, 0.0314,\n",
      "         0.0376, 0.0412, 0.0464, 0.0532, 0.0559, 0.0452, 0.0342, 0.0211, 0.0250,\n",
      "         0.0316, 0.0354, 0.0322, 0.0278, 0.0300, 0.0443, 0.0587, 0.0564, 0.0404,\n",
      "         0.0275, 0.0282, 0.0236, 0.0303, 0.0316, 0.0319, 0.0270, 0.0259, 0.0273,\n",
      "         0.0477, 0.0446, 0.0352, 0.0227, 0.0289, 0.0238, 0.0219, 0.0269, 0.0298,\n",
      "         0.0252, 0.0275, 0.0247, 0.0400, 0.0367, 0.0217, 0.0218, 0.0325, 0.0421,\n",
      "         0.0446, 0.0274, 0.0132, 0.0232, 0.0350, 0.0449, 0.0357, 0.0202, 0.0010,\n",
      "         0.0000, 0.0208, 0.0402, 0.0307, 0.0066, 0.0000, 0.0262, 0.0338, 0.0200,\n",
      "         0.2625, 0.4051, 0.1250, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x1=batch['PhantomRGB']\n",
    "x2=batch['Non_uniform_input']\n",
    "\n",
    "x1=model.encoder_conv(x1)\n",
    "x1=model.flatten(x1)\n",
    "#Pre estimation\n",
    "print(torch.concat((x1,x2.squeeze(1).squeeze(1)),dim=1)) #CHECK\n",
    "x=model.pre_encoder(torch.concat((x1,x2.squeeze(1).squeeze(1)),dim=1))\n",
    "#FCNN\n",
    "mu=model.encoder_NN_mu(x)\n",
    "sig=model.encoder_NN_sig(x)\n",
    "\n",
    "z12=model.reparametrization(mu,sig)\n",
    "#Pre estimation inv\n",
    "\n",
    "z12=model.decoder_NN(z12)\n",
    "z12=model.post_encoder(z12) #TODO: split image and other input latent variables\n",
    "z1,z2=torch.split(z12,[model.NN_input,model.non_uniform_input_dim],dim=1)\n",
    "\n",
    "z1=model.flatten(z1)\n",
    "z1=model.decoder_conv(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c257e9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat((x1,x2.squeeze(1).squeeze(1)),dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90c42e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4cf0f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx=x2.squeeze(1).squeeze(1)\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2e8c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1,z2=torch.split(z12,[model.NN_input,model.non_uniform_input_dim],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ecd33e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0723, 0.0000, 0.0000, 0.0000, 0.0337, 0.0000, 0.0414, 0.0326, 0.0000,\n",
       "         0.0354, 0.0173, 0.0197, 0.0000, 0.0000, 0.0000, 0.0112, 0.0000, 0.0129,\n",
       "         0.0000, 0.0000, 0.0363, 0.0000, 0.1226, 0.0000, 0.0000, 0.0153, 0.0000,\n",
       "         0.0640, 0.0203, 0.0000, 0.0336, 0.0000]],\n",
       "       grad_fn=<SplitWithSizesBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paltas",
   "language": "python",
   "name": "paltas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
